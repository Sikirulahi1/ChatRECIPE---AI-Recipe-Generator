{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face model Speech to text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  I'm a vegetarian. I love cooked vegetables, but I don't know what's cooked. If I give me some recipe, I can use\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from pydub import AudioSegment\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Function to convert .m4a to .wav\n",
    "def convert_m4a_to_wav(audio_path):\n",
    "    \"\"\"Converts an .m4a file to .wav format.\"\"\"\n",
    "    if not os.path.exists(audio_path):\n",
    "        raise FileNotFoundError(f\"The file {audio_path} does not exist.\")\n",
    "    \n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    wav_path = audio_path.replace(\".m4a\", \".wav\")\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "    return wav_path\n",
    "\n",
    "# Function to load the Whisper model and processor\n",
    "def load_whisper_model(model_name=\"openai/whisper-tiny.en\"):\n",
    "    \"\"\"Loads the Whisper model and processor.\"\"\"\n",
    "    processor = WhisperProcessor.from_pretrained(model_name)\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "    model.config.forced_decoder_ids = None\n",
    "    return processor, model\n",
    "\n",
    "# Function to preprocess and transcribe audio\n",
    "def transcribe_audio(audio_path, processor, model):\n",
    "    \"\"\"Preprocesses and transcribes an audio file.\"\"\"\n",
    "    # Convert .m4a to .wav if necessary\n",
    "    if audio_path.endswith(\".m4a\"):\n",
    "        audio_path = convert_m4a_to_wav(audio_path)\n",
    "    \n",
    "    # Load the audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # Resample to 16 kHz if needed\n",
    "    if sample_rate != 16000:\n",
    "        resampler = transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Convert audio to input features\n",
    "    input_features = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "\n",
    "    # Generate token ids (set language='en' to force translation to English)\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    \n",
    "    # Decode token ids to text\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "    return transcription\n",
    "\n",
    "# Load the Whisper model and processor\n",
    "processor, model = load_whisper_model()\n",
    "\n",
    "# Path to your audio file\n",
    "audio_file = r\"C:\\Users\\USER\\Desktop\\Projects\\Recipe_Generator\\Notebooks\\recordings\\my_voice.wav\"\n",
    "\n",
    "# Transcribe the audio\n",
    "transcription = transcribe_audio(audio_file, processor, model)\n",
    "print(\"Transcription:\", transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording audio (Just to test the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak into the microphone.\n",
      "Recording complete.\n",
      "Audio saved to: recordings/my_voice.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "\n",
    "def record_audio(duration, save_path):\n",
    "    \"\"\"\n",
    "    Records audio from the microphone and saves it as a .wav file.\n",
    "\n",
    "    Parameters:\n",
    "        duration (int): Duration of the recording in seconds.\n",
    "        save_path (str): Path where the recorded audio will be saved (including filename).\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    save_dir = os.path.dirname(save_path)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Define the sampling rate\n",
    "    sampling_rate = 16000  # 16 kHz is commonly used for speech\n",
    "\n",
    "    print(\"Recording... Speak into the microphone.\")\n",
    "    # Record audio\n",
    "    audio_data = sd.rec(int(duration * sampling_rate), samplerate=sampling_rate, channels=1, dtype='int16')\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording complete.\")\n",
    "    \n",
    "    # Save the audio file\n",
    "    write(save_path, sampling_rate, audio_data)\n",
    "    print(f\"Audio saved to: {save_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    duration_in_seconds = 10  # Record for 10 seconds\n",
    "    save_file_path = \"recordings/my_voice.wav\"  # Specify the save directory and filename\n",
    "    record_audio(duration_in_seconds, save_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\Projects\\Recipe_Generator\\Notebooks\n",
      "c:\\Users\\USER\\Desktop\\Projects\\Recipe_Generator\\Notebooks\\recordings\\my_voice.wav\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()  # Get the current working directory\n",
    "print(current_directory)\n",
    "audio_file = os.path.join(current_directory, \"recordings\", \"my_voice.wav\")\n",
    "print(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Speak into the microphone.\n",
      "Recording complete.\n",
      "Transcription:  I'm gonna go to the hospital.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
