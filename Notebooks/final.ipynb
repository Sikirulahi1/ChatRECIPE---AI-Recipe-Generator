{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@tool\n",
    "def search_recipes(\n",
    "    query: str, \n",
    "    includeIngredients: str, \n",
    "    excludeIngredients: str, \n",
    "    diet: str, \n",
    "    cuisine: str, \n",
    "    addRecipeInformation: bool, \n",
    "    number: int,\n",
    ") -> dict:\n",
    "    \"\"\"Search for recipes based on various filters and preferences.\n",
    "\n",
    "    Args:\n",
    "        query: Search term for the recipe (e.g., 'pasta').\n",
    "        includeIngredients: Ingredients that must be included in the recipes (comma-separated).\n",
    "        excludeIngredients: Ingredients to exclude from the recipes (comma-separated).\n",
    "        diet: Dietary preference (e.g., 'vegetarian').\n",
    "        cuisine: Cuisine type (e.g., 'italian').\n",
    "        addRecipeInformation: Whether to include detailed recipe information (True/False).\n",
    "        number: Number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the search results.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"includeIngredients\": includeIngredients,\n",
    "        \"excludeIngredients\": excludeIngredients,\n",
    "        \"diet\": diet,\n",
    "        \"cuisine\": cuisine,\n",
    "        \"addRecipeInformation\": addRecipeInformation,\n",
    "        \"number\": number\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_ingredient_substitutes(\n",
    "    ingredient_name: str\n",
    ") -> dict:\n",
    "    \"\"\"Fetches ingredient substitutes from the Spoonacular API.\n",
    "\n",
    "    Args:\n",
    "        ingredient_name (str): The name of the ingredient to find substitutes for.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the substitutes and relevant information.\n",
    "    \"\"\"\n",
    "    # Return parameters for fetching substitutes\n",
    "    result = {\n",
    "        \"ingredient_name\": ingredient_name\n",
    "    }\n",
    "    return result\n",
    "\n",
    "@tool\n",
    "def conversation(query: str) -> str:\n",
    "    \"\"\"This function simply returns the input query as part of a normal conversation.\"\"\"\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def fetch_recipes(parameters):\n",
    "    # API Key and URL\n",
    "    API_KEY = os.getenv(\"SPOONACULAR_API_KEY\")\n",
    "    BASE_URL = \"https://api.spoonacular.com/recipes/complexSearch\"\n",
    "\n",
    "    # Parameters for the search\n",
    "    params = {\n",
    "        \"query\": parameters['query'],\n",
    "        \"includeIngredients\": parameters['includeIngredients'],\n",
    "        \"excludeIngredients\": parameters['excludeIngredients'],\n",
    "        \"diet\": parameters['diet'],\n",
    "        \"cuisine\": parameters['cuisine'],\n",
    "        \"addRecipeInformation\": parameters['addRecipeInformation'],\n",
    "        \"number\": parameters['number'],\n",
    "        \"apiKey\": API_KEY\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    # Check the response status and return results\n",
    "    if response.status_code == 200:\n",
    "        recipes = response.json()\n",
    "        return recipes\n",
    "    else:\n",
    "        return {\n",
    "            \"error\": f\"Failed to fetch recipes: {response.status_code}\",\n",
    "            \"details\": response.json()\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def fetch_substitutes(parameter: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Makes an API request to fetch substitutes for a given ingredient.\n",
    "\n",
    "    Args:\n",
    "        parameter (dict): A dictionary containing 'ingredient_name' and 'api_key'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the substitutes or error details.\n",
    "    \"\"\"\n",
    "\n",
    "    # API base URL\n",
    "    BASE_URL = \"https://api.spoonacular.com/food/ingredients/substitutes\"\n",
    "    API_KEY = os.getenv(\"SPOONACULAR_API_KEY\")\n",
    "\n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        \"ingredientName\": parameter[\"ingredient_name\"],\n",
    "        \"apiKey\": API_KEY\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API request\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "        # Validate response status\n",
    "        if response.status_code == 200:\n",
    "            substitutes = response.json()\n",
    "            return {\n",
    "                \"substitutes\": substitutes.get(\"substitutes\", []),\n",
    "                \"message\": substitutes.get(\"message\"),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"error\": f\"Failed to fetch substitutes. Status code: {response.status_code}\",\n",
    "                \"details\": response.json(),\n",
    "            }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle network-related errors\n",
    "        return {\"error\": f\"An error occurred while making the API request: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def get_ai_response(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Get AI response using LangChain and OpenAI.\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): User input text/question\n",
    "        \n",
    "    Returns:\n",
    "        str: AI generated response\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "\n",
    "    os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "    os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "\n",
    "    # Prompt Template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are a friendly and intelligent assistant. You can provide helpful answers, engage in casual conversation, and be thoughtful and patient with your responses. Feel free to ask follow-up questions if needed.\"),\n",
    "            (\"user\", \"I need assistance with: {question}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    llm = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "    output_parser = StrOutputParser()\n",
    "    chain = prompt|llm|output_parser\n",
    "\n",
    "    if input_text:\n",
    "        result = chain.invoke({\"question\": input_text})\n",
    "        return result\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def get_recipe_details(url):\n",
    "    \"\"\"\n",
    "    Retrieves and analyzes recipe details from a given URL using LangChain and Cohere.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the recipe webpage to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Detailed response containing ingredients and instructions\n",
    "    \"\"\"\n",
    "    # Load the webpage content\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Initialize API key (ensure the COHERE_API_KEY environment variable is set)\n",
    "    os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "    # Split the documents into chunks for processing\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Initialize Cohere LLM\n",
    "    llm = Cohere(\n",
    "        temperature=0.7,\n",
    "        max_tokens=300  # Adjust the token limit as needed\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"input\"],\n",
    "        template=\"\"\"\n",
    "        You are a highly intelligent and helpful assistant specialized in providing precise and insightful answers based on the given context. Always base your response strictly on the provided information and include step-by-step reasoning to ensure clarity and accuracy. Avoid assumptions and external knowledge unless explicitly asked for.\n",
    "\n",
    "        Here is the context for your response:\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "        \n",
    "        Now, answer the following question:\n",
    "        Question: {input}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the LLM chain with the prompt template\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Process the documents to get the ingredients and preparation steps\n",
    "    response = chain.run({\"context\": \"\\n\".join([doc.page_content for doc in documents]), \"input\": \"Ingredients and Preparation Steps\"})\n",
    "\n",
    "    return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_cohere import ChatCohere\n",
    "# import os\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# os.environ[\"COHERE_API_KEY\"] = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "\n",
    "# llm = ChatCohere(model=\"command-r-plus-04-2024\")\n",
    "\n",
    "# tools = [search_recipes, search_ingredient_substitutes]\n",
    "# llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# query = \"I want a vegetarian recipe that includes mushrooms and spinach, excludes dairy and nuts, is high in protein, and takes less than 30 minutes to prepare. Provide 3 detailed results with nutritional information.\"\n",
    "\n",
    "# parameters = llm_with_tools.invoke(query).tool_calls\n",
    "\n",
    "# tool_name = parameters[0]['name']\n",
    "\n",
    "# if tool_name == \"search_ingredient_substitutes\":\n",
    "#     tool_args = parameters[0]['args']\n",
    "#     substitutes = fetch_substitutes(tool_args)\n",
    "#     for substitute in substitutes.get(\"substitutes\", []):\n",
    "#         print(substitute)\n",
    "# elif tool_name == \"search_recipes\":\n",
    "#     tool_args = parameters[0]['args']\n",
    "#     recipes = fetch_recipes(tool_args)\n",
    "#     print(recipes)\n",
    "#     for recipe in recipes['results']:\n",
    "#         print(recipe['title'])\n",
    "#         print(recipe['sourceUrl'])\n",
    "#         print(recipe['image'])\n",
    "#         print(get_recipe_details(recipe['sourceUrl']))\n",
    "#         print(\"-\" * 30)\n",
    "# else:\n",
    "#     print(\"Invalid tool call\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mushroom Hummus Crostini\n",
      "https://www.foodista.com/recipe/DMRJSD86/mushroom-crostini-with-harissa-hummus\n",
      "https://img.spoonacular.com/recipes/1095745-312x231.jpg\n",
      "The ingredients for Mushroom Crostini with Harissa Hummus are as follows:\n",
      "\n",
      "- Crostini: 1 loaf thin, crusty bread (such as a french stick)\n",
      "- Mushrooms: 500g sliced\n",
      "- Spinach: 2-3 handfuls\n",
      "- Hummus: 1 14oz can chickpeas, 1 clove garlic, 1 tbsp lemon juice, 1 tbsp tahini, 1 tbsp olive oil, 2-3 tbsp water, 1/4 tsp ground cumin, 2-3 tbsp harissa paste (adjust depending on how spicy you want the hummus)\n",
      "\n",
      "The preparation steps are as follows:\n",
      "\n",
      "1. To make the hummus, place all ingredients in a food processor and blend until smooth. Adjust the amount of water and harissa pasta depending on how thick and spicy you want your hummus. It should still be spreadable. Set the hummus aside.\n",
      "2. Slice the mushrooms and fry them in a shallow pan until they are golden and crispy. Once they are ready, push them to one side of the pan and add the spinach to wilt.\n",
      "3. To assemble the crostini, spread some hummus on a slice of the bread (you can toast it if you like), then top with some spinach and mushrooms. Serve immediately. \n",
      "\n",
      "Enjoy your Mushroom Crostini with Harissa Hummus! \n",
      "------------------------------\n",
      "Miso Soup With Thin Noodles\n",
      "https://www.foodista.com/recipe/BYJ4Q2M5/miso-soup-with-thin-noodles\n",
      "https://img.spoonacular.com/recipes/652078-312x231.jpg\n",
      "The ingredients for the soup are:\n",
      "\n",
      "- 2 cups of water\n",
      "- A bunch of fresh spinach\n",
      "- 1/2 of a block of firm tofu\n",
      "- 8 shitaki mushrooms, cut up lengthwise\n",
      "- 2 small chives, cut into squares\n",
      "- 1 yellow onion, chopped up\n",
      "- 1/2 package of Thai Kitchen thin rice noodles\n",
      "- 1 ginger\n",
      "- 1 parsnip, cut up\n",
      "- 6 baby carrots, cut up\n",
      "- 1 zucchini, cut up\n",
      "- A pinch of red pepper flakes\n",
      "- A pinch of ginger powder\n",
      "\n",
      "The preparation steps are:\n",
      "\n",
      "1. After the miso has been prepared, start adding the ingredients to the soup pot. It can be your preference, but Serena Norr, the creator of this recipe, opted to start with the onions and chives and then added the zucchini, parsnip, carrots, mushrooms, and ginger. \n",
      "2. Cover the pot and let cook on a low flame for 20-30 minutes, tasting as you go. \n",
      "3. Add the tofu and pasta, allowing the pasta to cook for 8-10 minutes. Taste the soup, adding red pepper and turn off the flame when ready. \n",
      "4. Place spinach on the bottom of your soup bowl; you can also place the spinach directly in the pot, but since it wilts so quickly, Serena usually does it this way. \n",
      "\n",
      "You can adjust the red pepper and ginger flavors\n",
      "------------------------------\n",
      "Alouette® Stuffed Mushroom Caps\n",
      "https://www.foodista.com/recipe/8LZ2BYQT/alouette-stuffed-mushroom-caps\n",
      "https://img.spoonacular.com/recipes/632252-312x231.jpg\n",
      "The ingredients for Alouette® Stuffed Mushroom Caps are:\n",
      "\n",
      "- 18 mushroom caps\n",
      "- 1 package (6.5 oz.) Alouette Garlic & Herbs or Alouette Spinach & Artichoke Spread\n",
      "- 3 tablespoons seasoned bread crumbs\n",
      "\n",
      "The preparation steps are:\n",
      "\n",
      "1. Preheat oven to 375º F.\n",
      "2. Place mushroom caps hollow side up on a baking sheet. Fill each cap with 1 tsp. Alouette Garlic & Herbs Spreadable Cheese and sprinkle with seasoned bread crumbs. \n",
      "3. Bake for 12-15 minutes. Garnish and serve. \n",
      "\n",
      "It is important to note that the recipe instructions recommend using Alouette Garlic & Herbs Spreadable Cheese, but Alouette Spinach & Artichoke Spread can be substituted. \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "cohere_key = os.getenv(\"COHERE_API_KEY\")\n",
    "if not cohere_key:\n",
    "    raise ValueError(\"COHERE_API_KEY is missing. Please add it to your .env file.\")\n",
    "os.environ[\"COHERE_API_KEY\"] = cohere_key\n",
    "\n",
    "# Initialize Cohere chat model\n",
    "llm = ChatCohere(model=\"command-r-plus-04-2024\")\n",
    "\n",
    "# Define tools\n",
    "tools = [search_recipes, search_ingredient_substitutes]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# User query\n",
    "query = \"I want a vegetarian recipe that includes mushrooms and spinach, excludes dairy and nuts, is high in protein, and takes less than 30 minutes to prepare. Provide 3 detailed results with nutritional information.\"\n",
    "\n",
    "# Invoke tools and handle tool calls\n",
    "try:\n",
    "    parameters = llm_with_tools.invoke(query).tool_calls\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking tools: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "if not parameters:\n",
    "    print(\"No tools were invoked. Please check the query.\")\n",
    "    exit(1)\n",
    "\n",
    "# Execute the appropriate tool based on the response\n",
    "tool_name = parameters[0].get('name', None)\n",
    "tool_args = parameters[0].get('args', {})\n",
    "\n",
    "if tool_name == \"search_ingredient_substitutes\":\n",
    "    result = fetch_substitutes(tool_args)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error fetching substitutes: {result['error']}\")\n",
    "    else:\n",
    "        print(result)\n",
    "elif tool_name == \"search_recipes\":\n",
    "    recipes = fetch_recipes(tool_args)\n",
    "    if \"error\" in recipes:\n",
    "        print(f\"Error fetching recipes: {recipes['error']}\")\n",
    "    else:\n",
    "        for recipe in recipes.get('results', []):\n",
    "            print(recipe.get('title', 'No title'))\n",
    "            print(recipe.get('sourceUrl', 'No URL'))\n",
    "            print(recipe.get('image', 'No image available'))\n",
    "            print(get_recipe_details(recipe.get('sourceUrl', '')))\n",
    "            print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"Invalid tool call\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ingredients for Mushroom Crostini with Harissa Hummus are:\n",
      "\n",
      "- 1 loaf Thin, Crusty Bread such as french stick\n",
      "- 500 g Mushrooms sliced\n",
      "- 2-3 handfuls Fresh Spinach\n",
      "- 1 14oz can chickpeas\n",
      "- 1 clove garlic\n",
      "- 1 tbsp Lemon Juice\n",
      "- 1 tbsp Tahini\n",
      "- 1 tbsp olive oil\n",
      "- 2-3 tbsp Water\n",
      "- 1/4 tsp Ground Cumin\n",
      "- 2-3 tbsp Harissa Paste adjust depending on how spicy you want the hummus\n",
      "\n",
      "The instructions for preparation are as follows:\n",
      "\n",
      "1. To make the hummus, place all ingredients in a food processor and blend until smooth. Adjust the amount of water and harissa pasta depending on how thick and spicy you want your hummus. It should still be spreadable. Set the hummus aside.\n",
      "2. Slice the mushrooms and fry in a shallow pan until they are golden and crispy. Once they are ready, push them to one side of the pan and add the spinach to wilt.\n",
      "3. To assemble the crostini, spread some hummus on a slice of the bread (you can toast it if you like), then top with some spinach and mushrooms. Serve immediately. \n",
      "\n",
      "Total cook time: 10 mins \n",
      "\n",
      "Please note that the recipe serves 4 and can be easily adjusted if preparing a larger batch. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_cohere.llms import Cohere\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "def get_recipe_details(url):\n",
    "    \"\"\"\n",
    "    Retrieves and analyzes recipe details from a given URL using LangChain and Cohere.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the recipe webpage to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Detailed response containing ingredients and instructions\n",
    "    \"\"\"\n",
    "    # Load the webpage content\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Initialize API key\n",
    "    os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "    # Split the document into smaller chunks for processing (reduce chunk size for efficiency)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=20)\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Limit the number of documents processed to reduce time complexity\n",
    "    documents = documents[:20]  # Process only the first 20 chunks (adjust as necessary)\n",
    "\n",
    "    # Create a vector store with FAISS\n",
    "    db = FAISS.from_documents(documents, CohereEmbeddings(model=\"embed-english-light-v3.0\"))\n",
    "\n",
    "    # Create the Cohere LLM object (adjust max_tokens to a reasonable limit for performance)\n",
    "    llm = Cohere(\n",
    "        temperature=0.7,\n",
    "        max_tokens=300  # Lower token limit to optimize performance\n",
    "    )\n",
    "\n",
    "    # Define the prompt template to extract the ingredients and preparation steps\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"input\"],\n",
    "        template=\"\"\"\n",
    "        You are a highly intelligent and helpful assistant specialized in providing precise and insightful answers based on the given context. Always base your response strictly on the provided information and include step-by-step reasoning to ensure clarity and accuracy. Avoid assumptions and external knowledge unless explicitly asked for.\n",
    "\n",
    "        Here is the context for your response:\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "        \n",
    "        Now, answer the following question:\n",
    "        Question: {input}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Create the document chain for querying\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    # Create the retriever from the FAISS vector store\n",
    "    retriever = db.as_retriever()\n",
    "\n",
    "    # Create the retrieval chain\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "    # Query the chain to retrieve recipe details (ingredients and preparation instructions)\n",
    "    response = retrieval_chain.invoke({\n",
    "        \"input\": \"What are the ingredients and the instructions or preparation for this recipe?\"\n",
    "    })\n",
    "\n",
    "    return response['answer']\n",
    "\n",
    "x = get_recipe_details(\"https://www.foodista.com/recipe/DMRJSD86/mushroom-crostini-with-harissa-hummus\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ingredients for the miso soup with thin noodles are laid out below:\n",
      "\n",
      "- 2 cups of water\n",
      "- A bunch of fresh spinach\n",
      "- 1/2 of a block of firm tofu\n",
      "- 8 shitaki mushrooms, cut up lengthwise\n",
      "- 2 small chives, cut into squares\n",
      "- 1 yellow onion, chopped up\n",
      "- 1/2 package of a  of Thai Kitchen Thin Rice Noodles\n",
      "- 1 ginger\n",
      "- 1 parsnip, cut up\n",
      "- 6 baby carrots, cut up\n",
      "- 1 zucchini, cut up\n",
      "- A pinch of red pepper flakes\n",
      "- A pinch of ginger powder\n",
      "\n",
      "Below are the steps on how to prepare the miso soup with thin noodles:\n",
      "\n",
      "1. After the miso has been prepared, start adding the \"stuff\" to the soup pot. It can be your preference, but I opted to start with the onions and chives and then added the zucchini, parsnip, carrots, mushrooms, and ginger. \n",
      "2. Cover the pot and let cook on a low flame for 20-30 minutes, tasting as you go. \n",
      "3. Add the tofu and pasta, allowing the pasta to cook for 8-10 minutes. Taste the soup, adding red pepper and turn off the flame when ready. \n",
      "4. Place spinach on the bottom of your soup bowl. You can also place the spinach directly in the pot, but since it wilts so quickly I usually do\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Cohere\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def get_recipe_details(url):\n",
    "    \"\"\"\n",
    "    Retrieves and analyzes recipe details from a given URL using LangChain and Cohere.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL of the recipe webpage to analyze\n",
    "        \n",
    "    Returns:\n",
    "        str: Detailed response containing ingredients and instructions\n",
    "    \"\"\"\n",
    "    # Load the webpage content\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Initialize API key (ensure the COHERE_API_KEY environment variable is set)\n",
    "    os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "    # Split the documents into chunks for processing\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "    documents = text_splitter.split_documents(docs)\n",
    "\n",
    "    # Initialize Cohere LLM\n",
    "    llm = Cohere(\n",
    "        temperature=0.7,\n",
    "        max_tokens=300  # Adjust the token limit as needed\n",
    "    )\n",
    "\n",
    "    # Define the prompt template for extracting ingredients and preparation\n",
    "    # prompt = PromptTemplate(\n",
    "    #     input_variables=[\"context\", \"input\"],\n",
    "    #     template=\"\"\"\n",
    "    #     You are an intelligent assistant that can analyze recipe content. Your task is to extract the ingredients and the preparation steps for the given recipe from the provided context.\n",
    "\n",
    "    #     Here is the context:\n",
    "    #     <context>\n",
    "    #     {context}\n",
    "    #     </context>\n",
    "\n",
    "    #     Now, please extract the ingredients and preparation steps. Provide the ingredients in a bullet-point format and the preparation steps in a numbered list.\n",
    "    #     \"\"\"\n",
    "    # )\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"input\"],\n",
    "        template=\"\"\"\n",
    "        You are a highly intelligent and helpful assistant specialized in providing precise and insightful answers based on the given context. Always base your response strictly on the provided information and include step-by-step reasoning to ensure clarity and accuracy. Avoid assumptions and external knowledge unless explicitly asked for.\n",
    "\n",
    "        Here is the context for your response:\n",
    "        <context>\n",
    "        {context}\n",
    "        </context>\n",
    "        \n",
    "        Now, answer the following question:\n",
    "        Question: {input}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the LLM chain with the prompt template\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # Process the documents to get the ingredients and preparation steps\n",
    "    response = chain.run({\"context\": \"\\n\".join([doc.page_content for doc in documents]), \"input\": \"Ingredients and Preparation Steps\"})\n",
    "\n",
    "    return response\n",
    "\n",
    "# x = get_recipe_details(\"https://www.foodista.com/recipe/BYJ4Q2M5/miso-soup-with-thin-noodles\")\n",
    "# print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.foodista.com/recipe/BYJ4Q2M5/miso-soup-with-thin-noodles\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ingredients for Mushroom Crostini with Harissa Hummus are as follows:\n",
    "\n",
    "# - Crostini: 1 loaf thin, crusty bread (such as French stick)\n",
    "# - Mushrooms: 500g sliced\n",
    "# - Spinach: 2-3 handfuls\n",
    "# - Hummus: 1 14oz can chickpeas, 1 clove garlic, 1 tbsp lemon juice, 1 tbsp tahini, 1 tbsp olive oil, 2-3 tbsp water, 1/4 tsp ground cumin, 2-3 tbsp harissa paste (adjust amounts depending on spiciness)\n",
    "\n",
    "# The preparation steps are as follows:\n",
    "\n",
    "# 1. To make the hummus, place all ingredients in a food processor and blend until smooth. Adjust the amount of water and harissa pasta depending on how thick and spicy you want your hummus. Set the hummus aside.\n",
    "# 2. Slice the mushrooms and fry them in a shallow pan until they are golden and crispy. Once they are ready, push them to one side of the pan and add the spinach to wilt.\n",
    "# 3. To assemble the crostini, spread some hummus on a slice of the bread (you can toast it if you like), then top with some spinach and mushrooms. Serve immediately. \n",
    "\n",
    "# Please note that the recipe serves 4 and can be adjusted according to your preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 cup = 7/8 cup shortening and 1/2 tsp salt\n",
      "1 cup = 7/8 cup vegetable oil + 1/2 tsp salt\n",
      "1/2 cup = 1/4 cup buttermilk + 1/4 cup unsweetened applesauce\n",
      "1 cup = 1 cup margarine\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "cohere_key = os.getenv(\"COHERE_API_KEY\")\n",
    "if not cohere_key:\n",
    "    raise ValueError(\"COHERE_API_KEY is missing. Please add it to your .env file.\")\n",
    "os.environ[\"COHERE_API_KEY\"] = cohere_key\n",
    "\n",
    "# Initialize Cohere chat model\n",
    "llm = ChatCohere(model=\"command-r-plus-04-2024\")\n",
    "\n",
    "# Define tools\n",
    "tools = [search_recipes, search_ingredient_substitutes]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# User query\n",
    "query = \"I want substitutes for butter\"\n",
    "\n",
    "# Invoke tools and handle tool calls\n",
    "parameters = llm_with_tools.invoke(query).tool_calls\n",
    "\n",
    "\n",
    "# Execute the appropriate tool based on the response\n",
    "tool_name = parameters[0].get('name', None)\n",
    "tool_args = parameters[0].get('args', {})\n",
    "\n",
    "if tool_name == \"search_ingredient_substitutes\":\n",
    "    result = fetch_substitutes(tool_args)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error fetching substitutes: {result['error']}\")\n",
    "    else:\n",
    "        for substitute in result['substitutes']:\n",
    "            print(substitute)\n",
    "        # bot_response = result\n",
    "elif tool_name == \"search_recipes\":\n",
    "    recipes = fetch_recipes(tool_args)\n",
    "    if \"error\" in recipes:\n",
    "        print(f\"Error fetching recipes: {recipes['error']}\")\n",
    "    else:\n",
    "        for recipe in recipes.get('results', []):\n",
    "            print(recipe.get('title', 'No title'))\n",
    "            print(recipe.get('sourceUrl', 'No URL'))\n",
    "            print(recipe.get('image', 'No image available'))\n",
    "            result = get_recipe_details(recipe.get('sourceUrl', ''))\n",
    "            print(result)\n",
    "\n",
    "            # bot_response = result\n",
    "else:\n",
    "    print(\"Invalid tool call\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
